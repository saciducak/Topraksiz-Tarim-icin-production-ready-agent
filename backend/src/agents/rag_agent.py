"""
Topraksƒ±z Tarƒ±m AI Agent - RAG Agent
Retrieves relevant information from the agricultural knowledge base.
"""
from .state import AgentState
from ..services.rag import search_knowledge_base, generate_answer
import logging

logger = logging.getLogger(__name__)


async def rag_node(state: AgentState):
    """
    RAG Agent Node - Searches knowledge base and generates answers.
    """
    logger.info("RAG agent starting retrieval...")
    settings = state.get("_settings")
    
    try:
        query = state.get("query", "")
        detections = state.get("detections", [])
        
        # 1. Build Search Query (Short & Focused)
        search_query = query
        if detections:
            # Create a simple search query based on detections
            detected_classes = [d['class_name'] for d in detections]
            search_query = f"{', '.join(detected_classes)} treatment symptoms control"
            logger.info(f"Targeted search query: {search_query}")
        
        if not search_query:
            # Fallback for empty state
            search_query = "tomato plant diseases general care"

        # 2. Search Knowledge Base
        search_results = await search_knowledge_base(search_query)
        summary = f"Found {len(search_results)} sources for: {search_query}"
        logger.info(summary)
        
        # 3. Build Comprehensive Analysis Prompt (The "System" Logic)
        # We use strict formatting to ensure the UI renders it beautifully
        detected_str = ', '.join([d['class_name'] for d in detections]) if detections else "belirtilmeyen durum"
        
        # Prepare sensor context
        sensor_data = state.get("sensor_data")
        sensor_context = ""
        if sensor_data:
            sensor_context = "\n**üå°Ô∏è IoT Sens√∂r Verileri:**\n"
            if sensor_data.get('ph'): 
                ph = float(sensor_data['ph'])
                note = "(Y√ºksek - Demir alƒ±mƒ±nƒ± engeller)" if ph > 7.5 else "(D√º≈ü√ºk)" if ph < 5.5 else "(Normal)"
                sensor_context += f"- pH: {ph} {note}\n"
            
            if sensor_data.get('ec'):
                ec = float(sensor_data['ec'])
                note = "(Y√ºksek Tuzluluk - Yanƒ±klara sebep olabilir)" if ec > 2.5 else "(Normal)"
                sensor_context += f"- EC: {ec} mS/cm {note}\n"
                
            if sensor_data.get('temperature'):
                t = float(sensor_data['temperature'])
                sensor_context += f"- Su Sƒ±caklƒ±ƒüƒ±: {t}¬∞C\n"

        analysis_prompt = (
            f"Sen uzman bir Ziraat M√ºhendisisin. Analiz edilen bitkide ≈üu durumlar tespit edildi: {detected_str}.\n"
            f"{sensor_context}\n"
            "A≈üaƒüƒ±daki **REFERANS BAƒûLAM** bilgisini ve (varsa) SENS√ñR verilerini kullanarak, bu durumla ilgili √áOK KAPSAMLI, AKADEMƒ∞K ve PRATƒ∞K bir rapor hazƒ±rla.\n"
            "√ñrneƒüin: Eƒüer g√∂rselde 'Kloroz' (sararma) varsa VE pH y√ºksekse, te≈ühisi 'Y√ºksek pH kaynaklƒ± Demir Eksikliƒüi' olarak koy.\n"
            "Eƒüer spesifik bir hastalƒ±k yoksa, genel bitki saƒülƒ±ƒüƒ± ve bakƒ±m √∂nerileri ver.\n\n"
            "**KESƒ∞N FORMAT KURALLARI (Buna Uyulmalƒ±):**\n"
            "1. Yanƒ±tƒ±n SADECE Markdown formatƒ±nda olacak.\n"
            "2. Asla JSON bloƒüu i√ßine alma.\n"
            "3. Asla 'ƒ∞≈üte raporunuz' gibi giri≈ü c√ºmleleri kurma. Direkt ba≈ülƒ±kla ba≈üla.\n"
            "4. ≈ûu ba≈ülƒ±klarƒ± kullan:\n\n"
            "# ü©∫ Hastalƒ±k/Durum Analizi\n"
            "[Durumun bilimsel ve pratik a√ßƒ±klamasƒ±]\n\n"
            "# üß¨ Biyolojik Nedenler\n"
            "[Hastalƒ±ƒüƒ±/Sorunu tetikleyen fakt√∂rler]\n\n"
            "# üíä Tedavi Planƒ±\n"
            "- **Kimyasal M√ºcadele:** [ƒ∞la√ß/Aktif madde √∂nerileri]\n"
            "- **Organik M√ºcadele:** [Doƒüal y√∂ntemler]\n"
            "- **K√ºlt√ºrel √ñnlemler:** [Bakƒ±m teknikleri]\n\n"
            "# üõ°Ô∏è Gelecek ƒ∞√ßin Koruma\n"
            "[Stratejik √∂nlemler]\n"
        )

        # 4. Generate Answer using LLM
        generated_answer = await generate_answer(
            query=search_query,
            context=search_results,
            settings=settings,
            custom_user_prompt=analysis_prompt
        )
        
        return {
            "rag_query": search_query,
            "rag_answer": generated_answer,  # Crucial: This maps to state['rag_answer']
            "rag_results": search_results,
            "error": None
        }

    except Exception as e:
        logger.error(f"RAG agent failed: {e}", exc_info=True)
        return {
            "rag_answer": "Analiz raporu olu≈üturulurken bir hata meydana geldi.",
            "rag_results": [],
            "error": str(e)
        }


async def get_rag_response(
    query: str,
    history: list = None,
    settings = None
) -> dict:
    """
    Standalone RAG function for chat interface.
    """
    from ..config import get_settings
    
    if settings is None:
        settings = get_settings()
    
    try:
        # Search knowledge base
        search_results = await search_knowledge_base(query, top_k=5, settings=settings)
        
        # Build context from history
        context_messages = []
        if history:
            for msg in history[-5:]:  # Last 5 messages
                context_messages.append(f"{msg.role}: {msg.content}")
        
        # Generate answer
        answer = await generate_answer(
            query=query,
            context=search_results,
            history=context_messages,
            settings=settings
        )
        
        return {
            "answer": answer,
            "sources": [
                {"title": r.get("title", ""), "score": r.get("score", 0)}
                for r in search_results
            ]
        }
        
    except Exception as e:
        logger.error(f"RAG response failed: {str(e)}")
        return {
            "answer": f"√úzg√ºn√ºm, yanƒ±t olu≈üturulurken bir hata olu≈ütu: {str(e)}",
            "sources": []
        }
